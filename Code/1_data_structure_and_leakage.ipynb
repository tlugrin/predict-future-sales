{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data structure and search for potential leakages\n",
    "\n",
    "Exploratory analysis of the test set compared to the train set, looking at identifying potential leakages that could improve predictions, or simply a specific structure of the test set that we want to reproduce when validating models with train set data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '../Data/'\n",
    "\n",
    "sales    = pd.read_csv(os.path.join(DATA_FOLDER, 'sales_train.csv.gz'))\n",
    "items    = pd.read_csv(os.path.join(DATA_FOLDER, 'items.csv'))\n",
    "item_cat = pd.read_csv(os.path.join(DATA_FOLDER, 'item_categories.csv'))\n",
    "shops    = pd.read_csv(os.path.join(DATA_FOLDER, 'shops.csv'))\n",
    "test     = pd.read_csv(os.path.join(DATA_FOLDER, 'test.csv.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform date column and split day - month - year\n",
    "sales.loc[:, \"date\"] = pd.to_datetime(sales[\"date\"], format=\"%d.%m.%Y\")\n",
    "sales.loc[:, \"day\"] = sales[\"date\"].dt.day\n",
    "sales.loc[:, \"month\"] = sales[\"date\"].dt.month\n",
    "sales.loc[:, \"year\"] = sales[\"date\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Train set***\n",
      "Sales data frame:\n",
      "(2935849, 9)\n",
      "date               1034\n",
      "date_block_num       34\n",
      "shop_id              60\n",
      "item_id           21807\n",
      "item_price        19993\n",
      "item_cnt_day        198\n",
      "day                  31\n",
      "month                12\n",
      "year                  3\n",
      "dtype: int64\n",
      "Shops data frame:\n",
      "(60, 2)\n",
      "shop_name    60\n",
      "shop_id      60\n",
      "dtype: int64\n",
      "\n",
      "*** Test set***\n",
      "(214200, 3)\n",
      "ID         214200\n",
      "shop_id        42\n",
      "item_id      5100\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"***Train set***\")\n",
    "print(\"Sales data frame:\")\n",
    "print(sales.shape)\n",
    "print(sales.nunique())\n",
    "print(\"Shops data frame:\")\n",
    "print(shops.shape)\n",
    "print(shops.nunique())\n",
    "print(\"\\n*** Test set***\")\n",
    "print(test.shape)\n",
    "print(test.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the number of rows in the test set corresponds to the product of unique item ID's with unique shop ID's. This hints at how the test set was built: all combinations of items/shops are represented, and we thus expect many zeroes. We'll need to reproduce this structure and augment the train set such that each month has all item/shop combinations that appear in that month.\n",
    "\n",
    "What are systematic differences between the train and test sets? Are there shops or items that only appear in the test set, for example a shop that opened in November 2015, or a new item launched during that month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shop ID's...\n",
      "...in train set but not in test set: [23, 27, 29, 0, 1, 8, 13, 30, 32, 54, 43, 51, 17, 9, 40, 33, 20, 11]\n",
      "...in test set but not in train set (argh!): []\n",
      "item ID's...\n",
      "...in train set but not in test set: [2552, 2554, 2555, 2564, 2565, 2572, 2573, 2593, 2604, 2609]... (n = 17070)\n",
      "...in test set but not in train set (argh!): [5320, 5268, 5826, 3538, 3571, 3604, 3407, 3408, 3405, 3984]... (n = 363)\n"
     ]
    }
   ],
   "source": [
    "# coverage of train set over test set\n",
    "def get_coverage(train_set, test_set, key):\n",
    "    train_unique = train_set[key].unique()\n",
    "    test_unique  = test_set[key].unique()\n",
    "    overcoverage = []\n",
    "    undercoverage = []\n",
    "    \n",
    "    for id in train_unique:\n",
    "        if not id in test_unique:\n",
    "            overcoverage.append(id)\n",
    "    \n",
    "    for id in test_unique:\n",
    "        if not id in train_unique:\n",
    "            undercoverage.append(id)\n",
    "            \n",
    "    return (overcoverage, undercoverage)\n",
    "            \n",
    "overcoverage, undercoverage = get_coverage(sales, test, \"shop_id\")\n",
    "\n",
    "print(\"shop ID's...\")\n",
    "print(\"...in train set but not in test set:\", overcoverage)\n",
    "print(\"...in test set but not in train set (argh!):\", undercoverage)\n",
    "\n",
    "overcoverage, undercoverage = get_coverage(sales, test, \"item_id\")\n",
    "\n",
    "print(\"item ID's...\")\n",
    "print(\"...in train set but not in test set: %s... (n = %s)\"%(overcoverage[:10], len(overcoverage)))\n",
    "print(\"...in test set but not in train set (argh!): %s... (n = %s)\" %(undercoverage[:10], len(undercoverage)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We investigate whether items present in the test set but absent from the train set have enough coverage when looking at categories, so that category information can be leveraged to make predictions for items unknown to the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40    564652\n",
      "30    351591\n",
      "55    339585\n",
      "19    208219\n",
      "37    192674\n",
      "23    146789\n",
      "28    121539\n",
      "20     79058\n",
      "63     53845\n",
      "65     53227\n",
      "72     47177\n",
      "75     42603\n",
      "67     41706\n",
      "64     37635\n",
      "70     35484\n",
      "3      25283\n",
      "49     23708\n",
      "31     20649\n",
      "25     18576\n",
      "24     14891\n",
      "58     13702\n",
      "29     12257\n",
      "61     12237\n",
      "56      7931\n",
      "12      7402\n",
      "47      5657\n",
      "15      5360\n",
      "45      5234\n",
      "54      5175\n",
      "7       4459\n",
      "76      3746\n",
      "77      3703\n",
      "42      2835\n",
      "78      2346\n",
      "16      2247\n",
      "44       248\n",
      "36        19\n",
      "27         8\n",
      "0          3\n",
      "Name: item_category_id, dtype: int64\n",
      "40    32340\n",
      "55    28224\n",
      "37    13902\n",
      "31    11634\n",
      "58     9366\n",
      "      ...  \n",
      "11       42\n",
      "79       42\n",
      "71       42\n",
      "74       42\n",
      "0        42\n",
      "Name: item_category_id, Length: 62, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# category id coverage for missing items in train set\n",
    "sales_w_category = sales.merge(items, \"left\", \"item_id\")\n",
    "test_w_category = test.merge(items, \"left\", \"item_id\")\n",
    "cat_missing_items = test_w_category[test_w_category[\"item_id\"].isin(undercoverage)].item_category_id.unique()\n",
    "train_missing = sales_w_category[sales_w_category[\"item_category_id\"].isin(cat_missing_items)]\n",
    "print(train_missing.item_category_id.value_counts())\n",
    "print(test_w_category.item_category_id.value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
